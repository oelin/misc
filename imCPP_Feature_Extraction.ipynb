{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43635c87-3efc-4c09-982d-fdb2c9a52e8a",
   "metadata": {},
   "source": [
    "# imCPP: Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9a3f6e9-c77e-42bc-b046-18fda9a9abc3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "    from typing import List, Tuple\n",
    "    import gzip\n",
    "    import numpy as np\n",
    "    from dataclasses import dataclass\n",
    "\n",
    "    @dataclass\n",
    "    class DatasetParameters:\n",
    "        map_width: int = 10\n",
    "        map_count: int = 600\n",
    "        problem_count: int = 10\n",
    "        obstacle_count: int = 10\n",
    "        agent_count: int = 4\n",
    "\n",
    "\n",
    "    def bits_to_bytes(data: str) -> bytes:    \n",
    "        return bytes([int(data[i * 8 : (i + 1) * 8], 2) for i in range(len(data) // 8)])\n",
    "\n",
    "\n",
    "\n",
    "    def bytes_to_bits(data: bytes) -> str:\n",
    "        return ''.join('{:08b}'.format(byte) for byte in data)\n",
    "\n",
    "\n",
    "    class DatasetEncoder:    \n",
    "\n",
    "        def __init__(\n",
    "            self,\n",
    "            parameters: DatasetParameters,\n",
    "        ):\n",
    "            self.map_width = parameters.map_width\n",
    "            self.map_count = parameters.map_count\n",
    "            self.problem_count = parameters.problem_count\n",
    "            self.obstacle_count = parameters.obstacle_count\n",
    "            self.agent_count = parameters.agent_count\n",
    "            self.coordinate_length = int(2 * np.ceil(np.log2(self.map_width)))\n",
    "            self.map_length = int(self.obstacle_count * self.coordinate_length)\n",
    "            self.problem_length = int(self.agent_count * self.coordinate_length)\n",
    "            self.solution_length = int(self.map_width ** 2) * 4\n",
    "\n",
    "\n",
    "        def encode_coordinate(self, coordinate: Tuple) -> str:\n",
    "            return ('{:0%ib}{:0%ib}' % (self.coordinate_length // 2, self.coordinate_length // 2)).format(*coordinate)\n",
    "\n",
    "\n",
    "        def decode_coordinate(self, data: str) -> str:\n",
    "            return int(data[: self.coordinate_length // 2], 2), int(data[self.coordinate_length // 2 :], 2)\n",
    "\n",
    "\n",
    "        def encode_coordinates(self, map: List) -> str:\n",
    "            return ''.join(self.encode_coordinate(obstacle) for obstacle in map)\n",
    "\n",
    "\n",
    "        def decode_coordinates(self, data: str) -> List:\n",
    "            return list(self.decode_coordinate(data[i * self.coordinate_length : (i + 1) * self.coordinate_length]) for i in range(len(data) // self.coordinate_length))\n",
    "\n",
    "\n",
    "        def encode_solution(self, solution: np.array) -> str:\n",
    "            return ''.join(str(bit) for bit in solution.flatten())\n",
    "\n",
    "\n",
    "        def decode_solution(self, data) -> np.array:\n",
    "            return np.array(list(data)).astype(int).reshape(self.agent_count, self.map_width, self.map_width)\n",
    "\n",
    "\n",
    "        def encode_dataset(self, maps: List, problems: List, solutions: List) -> str:\n",
    "\n",
    "            data = ''\n",
    "\n",
    "            for map in maps:\n",
    "                data += self.encode_coordinates(map)\n",
    "\n",
    "            for problem in problems:\n",
    "                data += self.encode_coordinates(problem)\n",
    "\n",
    "            for solution in solutions:\n",
    "                data += self.encode_solution(solution)\n",
    "\n",
    "\n",
    "            data += '0' * (len(data) % 8) # padding\n",
    "            return data \n",
    "\n",
    "\n",
    "        def decode_dataset(self, data: str) -> Tuple:\n",
    "\n",
    "            maps = [self.decode_coordinates(data[i * self.map_length : (i + 1) * self.map_length]) for i in range(self.map_count)]\n",
    "            data = data[self.map_count * self.map_length :]\n",
    "\n",
    "            problems = [self.decode_coordinates(data[i * self.problem_length : (i + 1) * self.problem_length]) for i in range(self.map_count * self.problem_count)]\n",
    "            data = data[self.map_count * self.problem_count * self.problem_length :]\n",
    "\n",
    "            solutions = [self.decode_solution(data[i * self.solution_length : (i + 1) * self.solution_length]) for i in range(self.map_count * self.problem_count)]\n",
    "            data = data[self.map_count * self.problem_count * self.solution_length :]\n",
    "\n",
    "            return maps, problems, solutions\n",
    "\n",
    "\n",
    "        def encode(self, maps: List, problems: List, solutions: List) -> bytes:\n",
    "            return gzip.compress(bits_to_bytes(self.encode_dataset(maps, problems, solutions)))\n",
    "\n",
    "\n",
    "        def decode(self, data: bytes) -> Tuple:\n",
    "            return self.decode_dataset(bytes_to_bits(gzip.decompress(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49c0fa60-9e2a-465b-85f0-5605a72dc292",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_parameters = DatasetParameters(\n",
    "    map_width=10,\n",
    "    map_count=600, # since some will not be solved\n",
    "    problem_count=50,\n",
    "    obstacle_count=10,\n",
    "    agent_count=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "728370dc-010f-4851-9d9f-a8a6c7062002",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_encoder = DatasetEncoder(dataset_parameters)\n",
    "\n",
    "def load_data(path: str) -> Tuple:\n",
    "    with open(path, 'rb') as file:\n",
    "        return dataset_encoder.decode(file.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0bd46bc-2d73-4e04-af15-07ff59f11171",
   "metadata": {},
   "source": [
    "We cast the problem of replicating DARP as a multi-label classification problem. To generate our features we use the following procedure:\n",
    "\n",
    "* While the map is not covered:\n",
    "    * For each agent:\n",
    "        * Pick a cell on the exterior of the agent's sub-area.\n",
    "        * Gather features $F$ for this cell (e.g. a FOV from the perspective of the cell).\n",
    "        * Check which adjacent cells are also in the agent's sub-area.\n",
    "        * Create a training example $(F, C)$ where $C$ is a multi-one-hot encoded label denoting which adjacent cells are included.\n",
    "        * Add the adjacent cells to the set of potential cells to explore for this agent.\n",
    "    * Update the map to contain newly explored cells."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf68f76-0377-4242-be0c-b079be30d770",
   "metadata": {},
   "source": [
    "It may be possible to inflate the dataset further by converting the multi-one-hot labels to *contrastive* labels. In this case, we train a model to predict whether two nodes are adjacent based on their embeddings. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324fd453-e2ad-4efc-8bc9-fdc33d38e55a",
   "metadata": {},
   "source": [
    "## Features For Cells"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33998dc7-913c-4c3f-af0b-2aae8d5f7dee",
   "metadata": {
    "tags": []
   },
   "source": [
    "A key part of this process is our selection of features for each cell. Ideally, we would like to find a set of *local* features which are highly informative towards the task of predicting whether adjacent cells are within an agent's sub-area. The locallity requirement is intended to increase generalization such that models do not rely heavily on the whole layout of a map. Two ideas come to mnid:\n",
    "\n",
    "1. Local FOV - we consider a small field-of-view arround each cell. The resulting image may have separate channels for other agents and covered cells.\n",
    "2. GNN features - we use a GNN to learn embeddings of cells based on surrounding cell features. The individual cells features could be DODGE features for instance.\n",
    "\n",
    "Both feature selections can potentially either be used for multi-label classification or contrastive classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fba48cb-e04b-4f7c-a3f3-563c854df3e9",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065f91ae-af7e-473a-9588-3d2813049886",
   "metadata": {},
   "source": [
    "We now implement the aforementioned method to create a multi-label classification dataset. We use DODGE features for each node. These will later be integrated into embeddings by a GNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bafde631-35cd-4048-9165-5575cd31d132",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_decoder():\n",
    "    \n",
    "    def decode(data):\n",
    "        from typing import List, Tuple\n",
    "        import gzip\n",
    "        import numpy as np\n",
    "        from dataclasses import dataclass\n",
    "\n",
    "        @dataclass\n",
    "        class DatasetParameters:\n",
    "            map_width: int = 10\n",
    "            map_count: int = 600\n",
    "            problem_count: int = 10\n",
    "            obstacle_count: int = 10\n",
    "            agent_count: int = 4\n",
    "\n",
    "\n",
    "        class DatasetEncoder:    \n",
    "\n",
    "            def __init__(\n",
    "                self,\n",
    "                parameters: DatasetParameters,\n",
    "            ):\n",
    "                self.map_width = parameters.map_width\n",
    "                self.map_count = parameters.map_count\n",
    "                self.problem_count = parameters.problem_count\n",
    "                self.obstacle_count = parameters.obstacle_count\n",
    "                self.agent_count = parameters.agent_count\n",
    "                self.coordinate_length = int(2 * np.ceil(np.log2(self.map_width)))\n",
    "                self.map_length = int(self.obstacle_count * self.coordinate_length)\n",
    "                self.problem_length = int(self.agent_count * self.coordinate_length)\n",
    "                self.solution_length = int(self.map_width ** 2) * 4\n",
    "\n",
    "            def decode_coordinates(self, data: str) -> List:\n",
    "                return list(self.decode_coordinate(data[i * self.coordinate_length : (i + 1) * self.coordinate_length]) for i in range(len(data) // self.coordinate_length))\n",
    "\n",
    "\n",
    "            def encode_solution(self, solution: np.array) -> str:\n",
    "                return ''.join(str(bit) for bit in solution.flatten())\n",
    "\n",
    "\n",
    "            def decode_solution(self, data) -> np.array:\n",
    "                return np.array(list(data)).astype(int).reshape(self.agent_count, self.map_width, self.map_width)\n",
    "\n",
    "\n",
    "            def decode_dataset(self, data: str) -> Tuple:\n",
    "\n",
    "                maps = [self.decode_coordinates(data[i * self.map_length : (i + 1) * self.map_length]) for i in range(self.map_count)]\n",
    "                data = data[self.map_count * self.map_length :]\n",
    "\n",
    "                problems = [self.decode_coordinates(data[i * self.problem_length : (i + 1) * self.problem_length]) for i in range(self.map_count * self.problem_count)]\n",
    "                data = data[self.map_count * self.problem_count * self.problem_length :]\n",
    "\n",
    "                solutions = [self.decode_solution(data[i * self.solution_length : (i + 1) * self.solution_length]) for i in range(self.map_count * self.problem_count)]\n",
    "                data = data[self.map_count * self.problem_count * self.solution_length :]\n",
    "\n",
    "                return maps, problems, solutions\n",
    "\n",
    "\n",
    "            def decode(self, data: bytes) -> Tuple:\n",
    "                return self.decode_dataset(bytes_to_bits(gzip.decompress(data)))\n",
    "\n",
    "\n",
    "        def bits_to_bytes(data: str) -> bytes:    \n",
    "            return bytes([int(data[i * 8 : (i + 1) * 8], 2) for i in range(len(data) // 8)])\n",
    "\n",
    "\n",
    "        def bytes_to_bits(data: bytes) -> str:\n",
    "            return ''.join('{:08b}'.format(byte) for byte in data)\n",
    "\n",
    "\n",
    "        dataset_parameters = DatasetParameters(\n",
    "                map_width=10,\n",
    "                map_count=600, # since some will not be solved\n",
    "                problem_count=50,\n",
    "                obstacle_count=10,\n",
    "                agent_count=4,\n",
    "        )\n",
    "\n",
    "\n",
    "        dataset_encoder = DatasetEncoder(dataset_parameters)\n",
    "        return dataset_encoder.decode(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "46dc8746-d86e-4fb9-9a52-e843a6c70cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, Any\n",
    "import dis\n",
    "import marshal\n",
    "import pickle\n",
    "\n",
    "\n",
    "Data = Any\n",
    "Decoder = Callable[None, Callable]\n",
    "\n",
    "\n",
    "def encode(data: Data, decoder: Decoder) -> Data:\n",
    "\n",
    "        decoder = dis.Bytecode(decoder)\n",
    "        decoder = marshal.dumps(decoder.codeobj)\n",
    "\n",
    "        return pickle.dumps((data, decoder))\n",
    "\n",
    "\n",
    "def decode(data: Data) -> Data:\n",
    "\n",
    "        data, decoder = pickle.loads(data)\n",
    "        decoder = marshal.loads(decoder)\n",
    "\n",
    "        return eval(decoder)(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9a907450-0987-4bb3-a210-200f245a7d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = open('../data/imcpp-0.gz', 'rb').read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "39cb381e-9641-4bb4-802e-d11842217887",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "809623"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open('./imcpp0.coco.gz', 'wb').write(gzip.compress(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc5f9f44-e81b-41c9-9984-c49bf6fb6ffd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset0 = load_data('../data/imcpp-0.gz')\n",
    "dataset1 = load_data('../data/imcpp-1.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "262db991-c9ac-4c16-87ff-f7e2cb6b44b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cityblock as manhattan_distance\n",
    "\n",
    "\n",
    "APF_FACTOR = 1 / dataset_parameters.agent_count\n",
    "MAX_AGENTS = 30\n",
    "\n",
    "\n",
    "def create_dodge_features(y, x, map: List, problem: List, solution: np.array, agent_index: int) -> np.array:\n",
    "    \n",
    "    agent_y, agent_x = problem[agent_index]\n",
    "\n",
    "    # Feature 0,1 - coordinate of the cell, relative to the agent.\n",
    "    # y_relative will be positive if the cell is below the agent.\n",
    "    # x_relative will be positive if the cell is to the right of the agent.\n",
    "\n",
    "    y_relative, x_relative = (y - agent_y, x - agent_x)\n",
    "\n",
    "\n",
    "    # Feature 2 - artificial potential field-based distance from other agents.\n",
    "    # w(cell) = sum_agent k/(dist(cell, agent) + 1)\n",
    "    # w(cell) = 0 if cell is an obstacle.\n",
    "\n",
    "    w = 0\n",
    "    is_obstacle = 0.\n",
    "\n",
    "    if (y, x) not in map: # (i.e. not an obstacle)\n",
    "        w = sum([ (APF_FACTOR / (manhattan_distance((y, x), agent) + 1)) for agent in problem ])\n",
    "\n",
    "    else:\n",
    "        is_obstacle = 1.\n",
    "\n",
    "\n",
    "    # Feature 3 - Occupancy of the cell.\n",
    "    # One-hot encode the index of the agent occupying the cell. All set to zero if no agents are occupying it. \n",
    "    # Last position set to 1 if occupied by an obstacle.\n",
    "\n",
    "    occupancy = np.zeros(MAX_AGENTS + 1)\n",
    "    occupancy[-1] = is_obstacle\n",
    "\n",
    "    for i, sub_area in enumerate(solution):\n",
    "        if sub_area[y, x]:\n",
    "            occupancy[i] = 1.\n",
    "\n",
    "    return (y_relative, x_relative, w, occupancy)         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa7cb64b-f03d-4ee1-ba9c-76172a2d275f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "FOV_RADIUS = 3\n",
    "FOV_WIDTH = FOV_RADIUS * 2 + 1\n",
    "FOV_CHANNELS = 3 # 4\n",
    "FOV_CHANNEL_OBSTACLE = 0\n",
    "FOV_CHANNEL_AGENT = 1\n",
    "FOV_CHANNEL_OTHER_AGENT = 2\n",
    "FOV_CHANNEL_OCCUPANCY = 3\n",
    "\n",
    "from numpy import linalg \n",
    "\n",
    "def compute_non_clipped_view(y, x, coordinates, exclude: set = set()):\n",
    "    \n",
    "    coordinates = list(set(coordinates) - exclude)\n",
    "    view = np.zeros((FOV_WIDTH, FOV_WIDTH))\n",
    "    \n",
    "    for (y1, x1) in coordinates:\n",
    "        \n",
    "        if (y1, x1) == (y, x):\n",
    "            view[FOV_RADIUS, FOV_RADIUS] = 1.\n",
    "        \n",
    "        elif abs(y1 - y) <= FOV_RADIUS and abs(x1 - x) <= FOV_RADIUS:\n",
    "\n",
    "            view_y = y1 - y + FOV_RADIUS\n",
    "            view_x = x1 - x + FOV_RADIUS\n",
    "            view[view_y, view_x] = 1.\n",
    "    \n",
    "    return view\n",
    "\n",
    "def compute_clipped_view(y, x, coordinates, exclude: set = set()):\n",
    "    \n",
    "    coordinates = list(set(coordinates) - exclude)\n",
    "    view = np.zeros((FOV_WIDTH, FOV_WIDTH))\n",
    "    \n",
    "    for (y1, x1) in coordinates:\n",
    "        \n",
    "        if (y1, x1) == (y, x):\n",
    "            view[FOV_RADIUS, FOV_RADIUS] = 1.\n",
    "        \n",
    "        elif abs(y1 - y) <= FOV_RADIUS and abs(x1 - x) <= FOV_RADIUS:\n",
    "\n",
    "            view_y = y1 - y + FOV_RADIUS\n",
    "            view_x = x1 - x + FOV_RADIUS\n",
    "            view[view_y, view_x] = 1.\n",
    "        \n",
    "        # otherwise, compute the projection...\n",
    "        \n",
    "        else:\n",
    "            projection_vector = np.array([y1 - y, x1 - x]).astype(float)\n",
    "            projection_vector /= np.linalg.norm(projection_vector)\n",
    "            ray_vector = np.zeros(2)\n",
    "            \n",
    "            while abs(ray_vector[0]) < FOV_RADIUS and abs(ray_vector[1]) < FOV_RADIUS:\n",
    "                ray_vector += projection_vector\n",
    "            \n",
    "            x_offset = int(max(-FOV_RADIUS, min(FOV_RADIUS, ray_vector[1])))\n",
    "            y_offset = int(max(-FOV_RADIUS, min(FOV_RADIUS, ray_vector[0])))\n",
    "            \n",
    "            projection_view_x = FOV_RADIUS + x_offset\n",
    "            projection_view_y = FOV_RADIUS + y_offset\n",
    "            view[projection_view_y, projection_view_x] = 1\n",
    "    \n",
    "    return view\n",
    "\n",
    "\n",
    "def create_fov_features(y, x, map: List, problem: List, solution: np.array, agent_index: int) -> np.array:\n",
    "    \n",
    "    agent_coordinate = problem[agent_index]\n",
    "    occupancy_map = solution.sum(axis=0).astype(bool).astype(int)\n",
    "\n",
    "    fov = np.zeros((FOV_CHANNELS, FOV_WIDTH, FOV_WIDTH))\n",
    "\n",
    "    fov[FOV_CHANNEL_OBSTACLE] = compute_non_clipped_view(y, x, map) # Channel 0 - non-clipped view of obstacles.\n",
    "    fov[FOV_CHANNEL_AGENT] = compute_clipped_view(y, x, [ agent_coordinate ]) # Channel 1 - clipped view of the agent.\n",
    "    fov[FOV_CHANNEL_OTHER_AGENT] = compute_clipped_view(y, x, problem, exclude={ agent_coordinate, }) # Channel 2 - clipped view of other agents.\n",
    "\n",
    "    # Add out of bounds obstacles...\n",
    "\n",
    "    for fov_y, y1 in enumerate(range(y - FOV_RADIUS, y + FOV_RADIUS + 1)):\n",
    "        for fov_x, x1 in enumerate(range(x - FOV_RADIUS, x + FOV_RADIUS + 1)):\n",
    "\n",
    "            if (y1 < 0) or (x1 < 0) or (y1 > dataset_parameters.map_width - 1) or (x1 > dataset_parameters.map_width - 1):\n",
    "                fov[FOV_CHANNEL_OBSTACLE, fov_y, fov_x] = 1.\n",
    "            \n",
    "            # elif occupancy_map[y1, x1]:\n",
    "            #     # Channel 3 - occupancy\n",
    "            #     fov[FOV_CHANNEL_OCCUPANCY][fov_y, fov_x] = 1.\n",
    "    \n",
    "    \n",
    "\n",
    "    return fov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66d9325c-d9f3-4341-8ae9-31ce3cecba75",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 1.],\n",
       "        [1., 0., 1., 0., 0., 0., 1.]],\n",
       "\n",
       "       [[0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_fov_features(0,7, dataset0[0][0], dataset0[1][0], dataset0[2][0], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "17d90e4c-caae-4dc2-af20-b70bc0ee55a2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-3,\n",
       " 0,\n",
       " 0.20833333333333331,\n",
       " array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_dodge_features(0, 5, dataset0[0][0], dataset0[1][0], dataset0[2][0], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "daf84ab2-8978-4877-832d-00dc03ba0bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def serialize_solution(map: List, problem: List, solution: np.array) -> np.array:\n",
    "    \n",
    "    exterior_cells = [[agent] for agent in problem]\n",
    "    visited_cells = {}\n",
    "    gradual_solution = np.zeros_like(solution)\n",
    "    finished = False\n",
    "    \n",
    "    # Add initial positions to gradual solution...\n",
    "    \n",
    "    for i, (y, x) in enumerate(problem):\n",
    "        gradual_solution[i, y, x] = 1.\n",
    "    \n",
    "    while not finished:\n",
    "        finished = True\n",
    "        \n",
    "        new_exterior_cells = [[] for _ in problem]\n",
    "        \n",
    "        for agent_index, agent in enumerate(problem):\n",
    "            \n",
    "            try:\n",
    "                exterior_cell = np.array(exterior_cells[agent_index].pop(0))\n",
    "                finished = False\n",
    "            except:\n",
    "                continue \n",
    "                \n",
    "            exterior_y, exterior_x = exterior_cell\n",
    "            #print(f'At cell {(exterior_y, exterior_x)}, agent {agent_index}, total explored cells = {len(visited_cells)}.')\n",
    "            visited_cells[(exterior_y, exterior_x)] = True\n",
    "            \n",
    "            features = create_fov_features(exterior_y, exterior_x, map, problem, gradual_solution, agent_index)\n",
    "            label = []\n",
    "            \n",
    "            for direction in [(-1, 0), (0, 1), (1, 0), (0, -1)]:\n",
    "                neighbour_y, neighbour_x = exterior_cell + direction\n",
    "                \n",
    "                if (neighbour_y < 0) or (neighbour_y >= dataset_parameters.map_width) or (neighbour_x < 0) or (neighbour_x >= dataset_parameters.map_width):\n",
    "                    label.append(0)\n",
    "                \n",
    "                else:\n",
    "                    neighbour_occupied = solution[agent_index, neighbour_y, neighbour_x]\n",
    "                    label.append(neighbour_occupied)\n",
    "                    \n",
    "                    if neighbour_occupied and not visited_cells.get((neighbour_y, neighbour_x)):\n",
    "                        \n",
    "                        #print(f'Adding {(neighbour_y, neighbour_x)} to exterior cells for agent {agent_index}...')\n",
    "                        new_exterior_cells[agent_index].append((neighbour_y, neighbour_x))\n",
    "            \n",
    "            yield features, label\n",
    "        \n",
    "        for i, cells in enumerate(new_exterior_cells):\n",
    "            exterior_cells[i] += cells\n",
    "            \n",
    "            for (y, x) in cells:\n",
    "                gradual_solution[i, y, x] = 1\n",
    "                \n",
    "    \n",
    "    \n",
    "# def serialize_solution(map: List, problem: List, solution: np.array) -> np.array:\n",
    "    \n",
    "#     fresh_cells = [[agent_start_cell] for agent_start_cell in problem]\n",
    "#     working_solution = np.zeros_like(solution)\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "#     # Add agent start cells to working solutotion\n",
    "    \n",
    "#     for i, (y, x) in enumerate(problem):\n",
    "#         working_solution[i, y, x] = 1.\n",
    "        \n",
    "    \n",
    "#     for step in range(5):\n",
    "#         for agent_index, (y, x) in enumerate(problem):\n",
    "            \n",
    "#             fresh_cell = fresh_cells[agent_index].pop(0)\n",
    "            \n",
    "#             input = create_fov_features(fresh_cell[0], fresh_cell[1], map, problem, working_solution, agent_index)\n",
    "#             label = [0]*4 # multi-label\n",
    "            \n",
    "#             for j, (dy, dx) in enumerate([(-1, 0), (0, 1), (1, 0), (0, -1)]): # N,E,S,W\n",
    "                \n",
    "#                 if is_cell_occupied_by_agent(agent_index, y + dy, x + dx):\n",
    "#                     label[j] = 1.\n",
    "#                     fresh_cells[agent_index].append((y + dy, x + dx))\n",
    "#                     #working_solution[agent_index, y + dy, x + dx] = 1.\n",
    "            \n",
    "#             print(fresh_cells)\n",
    "#             yield step, agent_index, input, label\n",
    "\n",
    "#     return working_solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "216fe447-26fc-428d-ac3d-08c694fce188",
   "metadata": {},
   "outputs": [],
   "source": [
    "map, problem, solution = dataset0[0][0], dataset0[1][0], dataset0[2][0]\n",
    "\n",
    "sol = serialize_solution(map, problem, solution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9a7300a3-92f2-4233-bd61-48be010bd852",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 1., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 1., 0., 1., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 1., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 1., 0.]],\n",
       " \n",
       "        [[0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 1., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "        [[0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 1., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 1., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 1., 0., 0.]]]),\n",
       " [0, 0, 1, 0])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(sol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d1cf02d9-7afd-4fd6-9478-fec5b09057e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serializing map 0 solutions...\n",
      "Serializing map 1 solutions...\n",
      "Serializing map 2 solutions...\n",
      "Serializing map 3 solutions...\n",
      "Serializing map 4 solutions...\n",
      "Serializing map 5 solutions...\n",
      "Serializing map 6 solutions...\n",
      "Serializing map 7 solutions...\n",
      "Serializing map 8 solutions...\n",
      "Serializing map 9 solutions...\n",
      "Serializing map 10 solutions...\n",
      "Serializing map 11 solutions...\n",
      "Serializing map 12 solutions...\n",
      "Serializing map 13 solutions...\n",
      "Serializing map 14 solutions...\n",
      "Serializing map 15 solutions...\n",
      "Serializing map 16 solutions...\n",
      "Serializing map 17 solutions...\n",
      "Serializing map 18 solutions...\n",
      "Serializing map 19 solutions...\n",
      "Serializing map 20 solutions...\n",
      "Serializing map 21 solutions...\n",
      "Serializing map 22 solutions...\n",
      "Serializing map 23 solutions...\n",
      "Serializing map 24 solutions...\n",
      "Serializing map 25 solutions...\n",
      "Serializing map 26 solutions...\n",
      "Serializing map 27 solutions...\n",
      "Serializing map 28 solutions...\n",
      "Serializing map 29 solutions...\n",
      "Serializing map 30 solutions...\n",
      "Serializing map 31 solutions...\n",
      "Serializing map 32 solutions...\n",
      "Serializing map 33 solutions...\n",
      "Serializing map 34 solutions...\n",
      "Serializing map 35 solutions...\n",
      "Serializing map 36 solutions...\n",
      "Serializing map 37 solutions...\n",
      "Serializing map 38 solutions...\n",
      "Serializing map 39 solutions...\n",
      "Serializing map 40 solutions...\n",
      "Serializing map 41 solutions...\n",
      "Serializing map 42 solutions...\n",
      "Serializing map 43 solutions...\n",
      "Serializing map 44 solutions...\n",
      "Serializing map 45 solutions...\n",
      "Serializing map 46 solutions...\n",
      "Serializing map 47 solutions...\n",
      "Serializing map 48 solutions...\n",
      "Serializing map 49 solutions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create training dataset\n",
    "\n",
    "train_x = []\n",
    "train_y = []\n",
    "\n",
    "# train on the first \n",
    "\n",
    "for i in range(dataset_parameters.map_count):\n",
    "    print(f'Serializing map {i} solutions...')\n",
    "    \n",
    "    for j in range(dataset_parameters.problem_count):\n",
    "        \n",
    "        map = dataset0[0][i]\n",
    "        problem = dataset0[1][dataset_parameters.problem_count * i + j]\n",
    "        solution = dataset0[2][dataset_parameters.problem_count * i + j]\n",
    "        \n",
    "        serialized_solution = serialize_solution(map, problem, solution)\n",
    "        \n",
    "        for features, labels in serialized_solution:\n",
    "            #x, y, w, o = features            \n",
    "            #features = np.concatenate(([x, y, w], o))\n",
    "            \n",
    "            train_x.append(features)\n",
    "            train_y.append(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1b022418-e975-454b-a10c-03255d46313b",
   "metadata": {},
   "outputs": [],
   "source": [
    "limit = 4_000_000\n",
    "\n",
    "train_y_limit = train_y[: limit]\n",
    "train_x_limit = train_x[: limit]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a660bea9-e942-4194-989b-a32273bd3d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y_north = [y[0] for y in train_y_limit]\n",
    "train_y_east = [y[1] for y in train_y_limit]\n",
    "train_y_south = [y[2] for y in train_y_limit]\n",
    "train_y_west = [y[3] for y in train_y_limit]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d5ed447b-5e18-4984-a810-467de5de5271",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_y_north\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "train_y_north.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8e8d5ae5-2740-4e77-9145-17ae155b40f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_limit = [x.flatten() for x in train_x_limit]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc20ed92-0910-4c24-aa29-b0222930f621",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "81de668d-e064-4dbf-90a9-94b08164ddcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "480477"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split = int(np.array(train_y_limit).shape[0] * 0.7)\n",
    "split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0695998e-45a7-4b34-b630-b4eab45c04b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480477, 205919)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_1, y_train_1 = train_x_limit[: split], train_y_north[: split]\n",
    "X_test_1, y_test_1 = train_x_limit[split :], train_y_north[split :]\n",
    "\n",
    "X_train_2, y_train_2 = train_x_limit[: split], train_y_east[: split]\n",
    "X_test_2, y_test_2 = train_x_limit[split :], train_y_east[split :]\n",
    "\n",
    "X_train_3, y_train_3 = train_x_limit[: split], train_y_south[: split]\n",
    "X_test_3, y_test_3 = train_x_limit[split :], train_y_south[split :]\n",
    "\n",
    "X_train_4, y_train_4 = train_x_limit[: split], train_y_west[: split]\n",
    "X_test_4, y_test_4 = train_x_limit[split :], train_y_west[split :]\n",
    "\n",
    "len(X_train_1), len(X_test_1)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5dd47e6e-ca09-4b08-ae20-28930b13d3d7",
   "metadata": {},
   "source": [
    "sum(train_y_north) / len(train_y_north)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "16ccd08f-90fa-463b-b5da-3a3e5c54a74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4ffb41ac-15fc-4192-94e4-5850deb987f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import CategoricalNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2f8a6adc-87ad-4f21-b196-ff5b5a6e0026",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2c6457e1-1750-40a3-8949-3a269e09fef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(max_iter=400).fit(X_train_1, y_train_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "325ff3a7-2d53-4dc3-91b4-1a21d9aee831",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.872255595646832"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test_1, y_test_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 884,
   "id": "403005ef-a80e-4749-96c1-0ec0c2c964cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(675817, 4, 7, 7)"
      ]
     },
     "execution_count": 884,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(X_train).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2167325a-cae3-4c4d-a853-0206710129f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training east...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training south...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training west...\n",
      "done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "clf1 = LogisticRegression().fit(X_train_1, y_train_1) # north classifier\n",
    "print('training east...')\n",
    "clf2 = LogisticRegression().fit(X_train_2, y_train_2) # eaast classifier\n",
    "print('training south...')\n",
    "clf3 = LogisticRegression().fit(X_train_3, y_train_3) # south classifier\n",
    "print('training west...')\n",
    "clf4 = LogisticRegression().fit(X_train_4, y_train_4) # west classificer\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "af6ae677-f0d9-4c85-8f4f-6e388807000f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.872255595646832"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test_1, y_test_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b3bf4cfe-c21d-40d6-a756-c24baf9072c8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def serialize_classifier_solution(map: List, problem: List, solution: List, classifiers: List) -> np.array:\n",
    "    \n",
    "    exterior_cells = [[agent] for agent in problem]\n",
    "    visited_cells = {}\n",
    "    gradual_solution = np.zeros_like(solution)\n",
    "    finished = False\n",
    "    \n",
    "    # Add initial positions to gradual solution...\n",
    "    \n",
    "    for i, (y, x) in enumerate(problem):\n",
    "        gradual_solution[i, y, x] = 1.\n",
    "    \n",
    "    for _ in range(200):\n",
    "        finished = True\n",
    "        yield gradual_solution\n",
    "        \n",
    "        new_exterior_cells = [[] for _ in problem]\n",
    "        \n",
    "        for agent_index, agent in enumerate(problem):\n",
    "            \n",
    "            try:\n",
    "                exterior_cell = np.array(exterior_cells[agent_index].pop(0))\n",
    "                finished = False\n",
    "            except:\n",
    "                continue \n",
    "                \n",
    "            exterior_y, exterior_x = exterior_cell\n",
    "            #print(f'At cell {(exterior_y, exterior_x)}, agent {agent_index}, total explored cells = {len(visited_cells)}.')\n",
    "            visited_cells[(exterior_y, exterior_x)] = True\n",
    "            \n",
    "            features = create_fov_features(exterior_y, exterior_x, map, problem, gradual_solution, agent_index)\n",
    "            features = features.flatten()\n",
    "            #label = []\n",
    "            \n",
    "            for classifier_index, direction in enumerate([(-1, 0), (0, 1), (1, 0), (0, -1)]):\n",
    "                neighbour_y, neighbour_x = exterior_cell + direction\n",
    "                \n",
    "                if (neighbour_y < 0) or (neighbour_y >= dataset_parameters.map_width) or (neighbour_x < 0) or (neighbour_x >= dataset_parameters.map_width):\n",
    "                    continue # ignore inaccessible cells\n",
    "                    \n",
    "                elif (neighbour_y, neighbour_x) in map:\n",
    "                    continue # ignore obstacles\n",
    "                \n",
    "                elif gradual_solution.sum(axis=0)[neighbour_y, neighbour_x]:\n",
    "                    continue\n",
    "                \n",
    "                else:\n",
    "                    predict_neighbour_occupied = classifiers[classifier_index].predict([ features ])\n",
    "                    #label.append(neighbour_occupied)\n",
    "                    \n",
    "                    if predict_neighbour_occupied and not visited_cells.get((neighbour_y, neighbour_x)): # note: decentralized agents might not have access to visited info.\n",
    "                        \n",
    "                        #print(f'Adding {(neighbour_y, neighbour_x)} to exterior cells for agent {agent_index}...')\n",
    "                        new_exterior_cells[agent_index].append((neighbour_y, neighbour_x))\n",
    "            \n",
    "            #yield features, label\n",
    "        \n",
    "        for i, cells in enumerate(new_exterior_cells):\n",
    "            exterior_cells[i] += cells\n",
    "            \n",
    "            for (y, x) in cells:\n",
    "                gradual_solution[i, y, x] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7aa9cb58-6bbb-4757-bf51-4c8d387b5b5a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "\n",
    "def draw_serialized_solution(\n",
    "    map,\n",
    "    problem,\n",
    "    solution, \n",
    "    agent_colours=[\n",
    "        (0xce, 0x71, 0xff), \n",
    "        (0x01, 0xcd, 0xfe), \n",
    "        (0x05, 0xff, 0xa1), \n",
    "        (0xff, 0xfb, 0x96),\n",
    "    ], \n",
    "    background_colour=(0x2c, 0x2f, 0x53),\n",
    "    obstacle_colour=(0xff, 0x00, 0x00),\n",
    "):\n",
    "    \n",
    "    for gradual_solution in solution:\n",
    "        image = Image.fromarray(np.ones((dataset_parameters.map_width, dataset_parameters.map_width)).astype('uint8') * 30).convert('RGB')\n",
    "        image = np.array(image)\n",
    "        \n",
    "        # draw obstacles\n",
    "        \n",
    "        for (y, x) in map:\n",
    "            image[y, x] = obstacle_colour\n",
    "\n",
    "        \n",
    "        for agent_index, agent_solution in enumerate(gradual_solution):\n",
    "            for y in range(dataset_parameters.map_width):\n",
    "                for x in range(dataset_parameters.map_width):\n",
    "                    if agent_solution[y, x]:\n",
    "                        image[y, x] = agent_colours[agent_index]\n",
    "        \n",
    "        # draw agents\n",
    "        \n",
    "        for (y, x) in problem:\n",
    "            image[y, x] = np.array((0xff, 0xff, 0xff))\n",
    "        \n",
    "        yield Image.fromarray(image.repeat(30, 0).repeat(30, 1))\n",
    "                        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7392f3ee-8192-4b35-8c47-a66f4bcbe61d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def draw_darp_solution(\n",
    "    map,\n",
    "    problem,\n",
    "    solution, \n",
    "    agent_colours=[\n",
    "        (0xce, 0x71, 0xff), \n",
    "        (0x01, 0xcd, 0xfe), \n",
    "        (0x05, 0xff, 0xa1), \n",
    "        (0xff, 0xfb, 0x96),\n",
    "    ], \n",
    "    background_colour=(0x2c, 0x2f, 0x53),\n",
    "    obstacle_colour=(0xff, 0x00, 0x00),\n",
    "):\n",
    "    \n",
    "\n",
    "    image = Image.fromarray(np.ones((dataset_parameters.map_width, dataset_parameters.map_width)).astype('uint8') * 30).convert('RGB')\n",
    "    image = np.array(image)\n",
    "\n",
    "\n",
    "    for agent_index, agent_solution in enumerate(solution):\n",
    "        for y in range(dataset_parameters.map_width):\n",
    "            for x in range(dataset_parameters.map_width):\n",
    "                if agent_solution[y, x]:\n",
    "                    image[y, x] = agent_colours[agent_index]\n",
    "    # draw obstacles\n",
    "\n",
    "    for (y, x) in map:\n",
    "        image[y, x] = obstacle_colour\n",
    "\n",
    "    # draw agents\n",
    "\n",
    "    for (y, x) in problem:\n",
    "        image[y, x] = np.array((0xff, 0xff, 0xff))\n",
    "        \n",
    "    return Image.fromarray(image.repeat(30, 0).repeat(30, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "34f2c599-06b1-44eb-8aca-87a392b5c877",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "map_i, p_i = 8, 23\n",
    "\n",
    "p_i = 50*map_i + p_i\n",
    "map, problem, solution = dataset0[0][map_i], dataset0[1][p_i], dataset0[2][p_i]\n",
    "sol1 = serialize_classifier_solution(map, problem, solution, [clf1, clf2, clf3, clf4])\n",
    "d = draw_serialized_solution(map, problem, sol1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7b55530b-f83c-4e81-b69d-1b428c5cb4f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAASwAAAEsCAIAAAD2HxkiAAAEFklEQVR4nO3dMW4TYRRGUY81znKQEvaT1NDBQqALtIHVUACroXEimwrJFJRPN0POWcCnkazrv3zL4fyw44/jcje0/PPdeWiZrdvXHwAvnQghJkKIiRBiIoSYCCEmQoiJEGIihJgIISZCiIkQYiKEmAghJkKIiRBiIoSYCCEmQoiJEGIihJgIISZCiIkQYiKEmAghJkKIiRBiIoTYWn/A8+J2Ev9y/XEZWvYSQkyEEBMhxEQIMRFCTIQQEyHERAgxEUJMhBATIcRECDERQkyEEBMhxEQIMRFCTIQQEyHERAgxEUJMhBATIcRECDERQkyEEBMhxEQIMRFCbDmcH+pveBG+vb+tP4FnyksIMRFCTIQQEyHERAgxEUJMhBATIcRECDERQkyEEBMhxEQIMRFCTIQQEyHERAgxEUJMhBATIcRECDERQkyEEBMhxEQIMRFCTIQQEyHERAgxV5k2z72nS9cfxqaXZWjYSwgxEUJMhBATIcRECDERQkyEEBMhxEQIMRFCTIQQEyHERAgxEUJMhBATIcRECDERQkyEEBMhxEQIMRFCTIQQEyHERAgxEUJMhBATIcRECLHBq0zH5W5o+colqQvHp19T04e3U8uP91PLG+QlhJgIISZCiIkQYiKEmAghJkKIiRBiIoSYCCEmQoiJEGIihJgIISZCiIkQYiKEmAghJkKIiRBiIoSYCCEmQoiJEGIihJgIISZCiIkQYiKE2LJ8Pw1Nrzdfh5bnHHe3Q8tXuy9Dy4NXmbZofTO1/PRpaNhLCDERQkyEEBMhxEQIMRFCTIQQEyHERAgxEUJMhBATIcRECDERQkyEEBMhxEQIMRFCTIQQEyHERAgxEUJMhBATIcRECDERQkyEEBMhxEQIscGrTFw6vZ76v9uP/YKnV5+HlrnkJYSYCCEmQoiJEGIihJgIISZCiIkQYiKEmAghJkKIiRBiIoSYCCEmQoiJEGIihJgIISZCiIkQYiKEmAghJkKIiRBiIoSYCCEmQoiJEGIihJirTH853SxDy/sf56HlOXOXpHaP91PLG+QlhJgIISZCiIkQYiKEmAghJkKIiRBiIoSYCCEmQoiJEGIihJgIISZCiIkQYiKEmAghJkKIiRBiIoSYCCEmQoiJEGIihJgIISZCiIkQYiKE2Dp3eWe/wXtPW7ydxNZ5CSEmQoiJEGIihJgIISZCiIkQYiKEmAghJkKIiRBiIoSYCCEmQoiJEGIihJgIISZCiIkQYiKEmAghJkKIiRBiIoSYCCEmQoiJEGIihJgIIbZu8XYS/E+8hBATIcRECDERQkyEEBMhxEQIMRFCTIQQEyHERAgxEUJMhBATIcRECDERQkyEEBMhxEQIMRFCTIQQEyHERAgxEUJMhBATIcRECDERQkyEEPsNeqA5r8OJO7IAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=300x300>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "draw_darp_solution(map,problem,solution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "24b43aae-12f0-478d-9fa2-c9b13c47b821",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAASwAAAEsCAIAAAD2HxkiAAAEFElEQVR4nO3dMW4TYRRGUY9lezlIgf3ENSVZCHSBNuwmBbAaGieyUyGlh+fLwDkL+DSSdf2Xb9lfHjb8clqOQ8s/PlyGllm7bf0B8L8TIcRECDERQkyEEBMhxEQIMRFCTIQQEyHERAgxEUJMhBATIcRECDERQkyEEBMhxEQIMRFCTIQQEyHERAgxEUJMhBATIcRECDERQkyEENvVH/B3OYzdqHq8GxrmSm4+LUPLXkKIiRBiIoSYCCEmQoiJEGIihJgIISZCiIkQYiKEmAghJkKIiRBiIoSYCCEmQoiJEGIihJgIISZCiIkQYiKEmAghJkKIiRBiIoSYCCEmQogt+7E7RFzH491t/Qn8Fi8hxEQIMRFCTIQQEyHERAgxEUJMhBATIcRECDERQkyEEBMhxEQIMRFCTIQQEyHERAgxEUJMhBATIcRECDERQkyEEBMhxEQIMRFCTIQQEyHEdvUHwJ9083FselmGhr2EEBMhxEQIMRFCTIQQEyHERAgxEUJMhBATIcRECDERQkyEEBMhxEQIMRFCTIQQEyHERAgxEUJMhBATIcRECDERQkyEEBMhxEQIMRFCTIQQW/aXh6Hp03IcWj6MfTOvzf2Cm6f7qeUV8hJCTIQQEyHERAgxEUJMhBATIcRECDERQkyEEBMhxEQIMRFCTIQQEyHERAgxEUJMhBATIcRECDERQkyEEBMhxEQIMRFCTIQQEyHERAgxEUJs8CrTGp02t0PLh83XoeXT88+h5VXavZ9afv48NOwlhJgIISZCiIkQYiKEmAghJkKIiRBiIoSYCCEmQoiJEGIihJgIISZCiIkQYiKEmAghJkKIiRBiIoSYCCEmQoiJEGIihJgIISZCiIkQYiKEmKtMV3JajkPL22/noeXzmy9Dy7zmJYSYCCEmQoiJEGIihJgIISZCiIkQYiKEmAghJkKIiRBiIoSYCCEmQoiJEGIihJgIISZCiIkQYiKEmAghJkKIiRBiIoSYCCEmQoiJEGIihNiyjN30WaPz22Voefv9MrQ85/xu7D/66X5qeYW8hBATIcRECDERQkyEEBMhxEQIMRFCTIQQEyHERAgxEUJMhBATIcRECDERQkyEEBMhxEQIMRFCTIQQEyHERAgxEUJMhBATIcRECDERQkyEENvNXd7ZrvDe0xpvJ7F2XkKIiRBiIoSYCCEmQoiJEGIihJgIISZCiIkQYiKEmAghJkKIiRBiIoSYCCEmQoiJEGIihJgIISZCiIkQYiKEmAghJkKIiRBiIoSYCCEmQojt1ng7Cf4lXkKIiRBiIoSYCCEmQoiJEGIihJgIISZCiIkQYiKEmAghJkKIiRBiIoSYCCEmQoiJEGIihJgIISZCiIkQYiKEmAghJkKIiRBiIoSYCCEmQoi9AOBxNBZPLy/MAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=300x300>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = list(d)\n",
    "f[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1920,
   "id": "2d5b72c9-4a01-4e31-95e8-9e29deb4efce",
   "metadata": {},
   "outputs": [],
   "source": [
    "sol1 = serialize_classifier_solution(map, problem, solution, [clf1, clf2, clf3, clf4])\n",
    "d = draw_serialized_solution(map, problem, sol1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1919,
   "id": "6539a11d-b2a8-4a6b-bfbe-29700c6cb768",
   "metadata": {},
   "outputs": [],
   "source": [
    "next(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22698c3-f8ac-486e-994a-352e0ed21b4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "25ebbc10-8093-4695-af41-46e9d80f96e4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f0667ef6-67e3-4c80-a9b0-a77b4dfabce8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 1, 1, 1, 1, 1, 0, 0, 0],\n",
       "        [0, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       "        [0, 0, 0, 0, 0, 1, 0, 1, 1, 1],\n",
       "        [0, 1, 1, 1, 1, 1, 1, 1, 0, 1],\n",
       "        [0, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "\n",
       "       [[1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, 0, 0, 1, 1, 1, 1, 1],\n",
       "        [0, 0, 0, 0, 0, 1, 1, 0, 1, 1],\n",
       "        [0, 0, 0, 0, 0, 1, 1, 1, 1, 1],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 1, 1, 1],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 1, 1, 1],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 1, 1, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset0[2][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04feb02-7829-4f09-86a6-8592e61517aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
